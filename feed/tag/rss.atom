<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>RyanCollins.org - rss</title><link href="https://ryancollins.org/" rel="alternate"></link><link href="https://ryancollins.org/feed/tag/rss.atom" rel="self"></link><id>https://ryancollins.org/</id><updated>2016-01-16T11:58:00-05:00</updated><entry><title>My Newsbeuter config file</title><link href="https://ryancollins.org/2016/01/16/my-newsbeuter-config-file/" rel="alternate"></link><published>2016-01-16T11:58:00-05:00</published><updated>2016-01-16T11:58:00-05:00</updated><author><name>mr_rcollins</name></author><id>tag:ryancollins.org,2016-01-16:/2016/01/16/my-newsbeuter-config-file/</id><summary type="html">&lt;p&gt;And here's my config file that I use with Newsbeuter.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;article-sort-order  date asc
auto-reload         yes
reload-time         60
show-read-feeds     no
show-read-articles  no
mark-as-read-on-hover   no
bookmark-cmd        &amp;quot;~/Development/bookmark&amp;quot;
bookmark-autopilot  no
save-path           &amp;quot;~/Documents/Research&amp;quot;
&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;And here's my config file that I use with Newsbeuter.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;article-sort-order  date asc
auto-reload         yes
reload-time         60
show-read-feeds     no
show-read-articles  no
mark-as-read-on-hover   no
bookmark-cmd        &amp;quot;~/Development/bookmark&amp;quot;
bookmark-autopilot  no
save-path           &amp;quot;~/Documents/Research&amp;quot;
&lt;/pre&gt;&lt;/div&gt;</content><category term="rss"></category><category term="newsbeuter"></category></entry><entry><title>Using RSS like it's 1990</title><link href="https://ryancollins.org/2016/01/15/using-rss-like-its-1990/" rel="alternate"></link><published>2016-01-15T13:46:04-05:00</published><updated>2016-01-15T13:46:04-05:00</updated><author><name>mr.rcollins</name></author><id>tag:ryancollins.org,2016-01-15:/2016/01/15/using-rss-like-its-1990/</id><summary type="html">&lt;p&gt;I'm a big console fan, preferring to do as much work as possible from the command line. So it shouldn't be surprised that I also use RSS even as others have abandoned it for things like Twitter. I prefer to supplement my news feeds with Twitter and not replace it …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm a big console fan, preferring to do as much work as possible from the command line. So it shouldn't be surprised that I also use RSS even as others have abandoned it for things like Twitter. I prefer to supplement my news feeds with Twitter and not replace it.&lt;/p&gt;
&lt;p&gt;Since the demise of Google Reader, I've settled on Feedly as my RSS reader. It's web interface has keyboard shortcuts, and the Reeder app works very well on my iPhone and iPad. But I think it could be faster&lt;/p&gt;
&lt;h1&gt;Back to 1990&lt;/h1&gt;
&lt;p&gt;Before web forums were all the rage, there was Usenet News. It was international, and distributed, which made it very resilient. It was also, for the most part, limited to text interfaces. There were several GUI interfaces for accessing Usenet, but for me, the command line application tin was all I needed. With it I could navigate an alarming amount of posts, selecting the ones I wanted to read while ignore the rest. It was pretty amazing how fast the whole process was. Alas, speed is something we lost on the transition to graphically interfaces.&lt;/p&gt;
&lt;h1&gt;Enter Newsbeuter&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://newsbeuter.org/"&gt;Newsbeuter&lt;/a&gt; is an open source command line RSS reader that can run on most UNIX based operating systems. A simple &lt;code&gt;sudo apt-get install newsbeuter&lt;/code&gt; installed it on my Ubuntu host, and I was good to go. I'm still in the honeymoon phase, so we'll see how long it lasts. To see it in action you can &lt;a href="http://newsbeuter.org/screenshots.html"&gt;check out the screenshots&lt;/a&gt; on the Newsbeuter site.&lt;/p&gt;</content><category term="rss"></category><category term="newsbeuter"></category></entry><entry><title>Google Reader shuts off tomorrow, use Google Takeout and Reader is Dead to backup</title><link href="https://ryancollins.org/2013/06/30/google-reader-shuts-off-tomorrow-use-google-takeout-and-reader-is-dead-to-backup/" rel="alternate"></link><published>2013-06-30T10:29:00-04:00</published><updated>2013-06-30T10:29:00-04:00</updated><author><name>mr.rcollins</name></author><id>tag:ryancollins.org,2013-06-30:/2013/06/30/google-reader-shuts-off-tomorrow-use-google-takeout-and-reader-is-dead-to-backup/</id><summary type="html">&lt;p&gt;Tomorrow Google Reader shuts off, have you grabbed your data? The easiest way to backup your subscriptions from Google Reader is to use &lt;a href="https://www.google.com/takeout/?pli=1"&gt;Google Takeout&lt;/a&gt;. This will give you a .zip file with a lot of data, including a subscriptions.xml which you can import into any RSS reader that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Tomorrow Google Reader shuts off, have you grabbed your data? The easiest way to backup your subscriptions from Google Reader is to use &lt;a href="https://www.google.com/takeout/?pli=1"&gt;Google Takeout&lt;/a&gt;. This will give you a .zip file with a lot of data, including a subscriptions.xml which you can import into any RSS reader that accepts an OPML file.&lt;/p&gt;
&lt;p&gt;This is fine for your list of subscriptions, but I have been using Google Reader as a particular search engine, allowing me to search for items that I have read. I lost this ability with Google Takeout, but then I came across &lt;a href="http://readerisdead.com/"&gt;Reader is Dead&lt;/a&gt;. Mihai Parparita has created a couple of scripts that back up not only your subscriptions, but also all the items in Google Reader. For me, it was 928,981 items to be downloaded.&lt;/p&gt;
&lt;p&gt;Under OS X the script ran right out of the box. If you are on Windows, you will need to install Python first.&lt;/p&gt;</content><category term="rss"></category><category term="googlereader"></category></entry><entry><title>Following lots of people on Twitter? You need ReadTwit</title><link href="https://ryancollins.org/2010/01/12/following-lots-of-people-on-twitter-you-need-readtwit/" rel="alternate"></link><published>2010-01-12T08:06:00-05:00</published><updated>2010-01-12T08:06:00-05:00</updated><author><name>mr.rcollins</name></author><id>tag:ryancollins.org,2010-01-12:/2010/01/12/following-lots-of-people-on-twitter-you-need-readtwit/</id><summary type="html">&lt;div style="float:right;"&gt;
[![10th November 314/365][]][]  
&lt;small&gt;[![Creative Commons License][]][] [photo][] credit:
[fifikins][]&lt;/small&gt;

&lt;/div&gt;

&lt;p&gt;A couple of months ago I decided to expand my use of Twitter, and began
following more and more people in the education community. This was
awesome, until I realized I could not keep up with the barrage of data …&lt;/p&gt;</summary><content type="html">&lt;div style="float:right;"&gt;
[![10th November 314/365][]][]  
&lt;small&gt;[![Creative Commons License][]][] [photo][] credit:
[fifikins][]&lt;/small&gt;

&lt;/div&gt;

&lt;p&gt;A couple of months ago I decided to expand my use of Twitter, and began
following more and more people in the education community. This was
awesome, until I realized I could not keep up with the barrage of data
that I was being given. In November I started brainstorming ideas on how
to keep up. I noticed in any of my twitter clients that they were not
grabbing all the tweets that had been posted from the last time I
checked. The reason being is the API only gives you the last 200 tweets,
and for me that was about 40 minutes worth.&lt;/p&gt;
&lt;p&gt;My first course of action was to write some software that would grab the
tweets from my [@mr_rcollins][] timeline, parse the info and store it
in a MySQL database. Besides pulling out the data I was interested in of
each tweet, I also stored the complete tweet. This became impractical,
since in a month the complete tweets themselves occupied 4.2GB! I
stopped storing the complete tweets which left me with a 20MB database
after a 5 weeks of collecting, which was a lot more manageable.&lt;/p&gt;
&lt;p&gt;The next step was to start parsing the tweet's text for urls, resolve
any shortened urls, and dump them into another table for me to peruse.
While I got that software working, I came across &lt;a href="http://readtwit.com"&gt;ReadTwit.com&lt;/a&gt;. This
is a great service that will take your timeline, parse out the urls,
resolve shortened links, and give you a RSS feed that you can subscribe
to in your favorite RSS reader (I use &lt;a href="http://google.com/read"&gt;Google Reader&lt;/a&gt;. Now I just go
through Reader like normal, and am able to tag/star important sites that
are posted to my Twitter timeline.&lt;/p&gt;
&lt;p&gt;[&lt;img alt="10th November 314/365" src="http://farm3.static.flickr.com/2763/4091878747_a0282c9255_m.jpg"&gt;]: http://www.flickr.com/photos/25925793@N00/4091878747/
    "10th November 314/365"
  [&lt;img alt="Creative Commons License" src="http://ryancollins.org/wp/wp-content/plugins/photo-dropper/images/cc.png"&gt;]: http://creativecommons.org/licenses/by/2.0/
    "Attribution License"&lt;/p&gt;</content><category term="rss"></category><category term="twitter"></category></entry><entry><title>Language arts teachers, take note, experience Bram Stoker's Dracula in real time</title><link href="https://ryancollins.org/2009/05/07/language-arts-teachers-take-note-experience-bram-stokers-dracula-in-real-time/" rel="alternate"></link><published>2009-05-07T12:24:00-04:00</published><updated>2009-05-07T12:24:00-04:00</updated><author><name>mr.rcollins</name></author><id>tag:ryancollins.org,2009-05-07:/2009/05/07/language-arts-teachers-take-note-experience-bram-stokers-dracula-in-real-time/</id><summary type="html">&lt;p&gt;&lt;a href="http://dracula-feed.blogspot.com/"&gt;Dracula&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Experience Bram Stoker's Dracula in a new way -- in real time. Dracula
is an epistolary novel (a novel written as a series of letters or
diary entries,) and this blog will publish each diary entry on the day
that it was written by the narrator so that the audience …&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://dracula-feed.blogspot.com/"&gt;Dracula&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Experience Bram Stoker's Dracula in a new way -- in real time. Dracula
is an epistolary novel (a novel written as a series of letters or
diary entries,) and this blog will publish each diary entry on the day
that it was written by the narrator so that the audience may
experience the drama as the characters would have.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What a cool way to introduce classic literature to student's brought up
with blogs and social networking. I've subscribed to the feed and can't
wait to read the novel through &lt;a href="http://google.com/reader/"&gt;Google Reader&lt;/a&gt;.&lt;/p&gt;
&lt;div class="zemanta-pixie"&gt;
![][]

&lt;/div&gt;

&lt;/p&gt;</content><category term="blog"></category><category term="dracula"></category><category term="google reader"></category><category term="rss"></category></entry></feed>