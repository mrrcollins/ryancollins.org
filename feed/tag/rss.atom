<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>RyanCollins.org</title><link href="http://ryancollins.org/" rel="alternate"></link><link href="http://ryancollins.org/feed/tag/rss.atom" rel="self"></link><id>http://ryancollins.org/</id><updated>2013-06-30T10:29:00-04:00</updated><entry><title>Google Reader shuts off tomorrow, use Google Takeout and Reader is Dead to backup</title><link href="http://ryancollins.org/2013/06/30/google-reader-shuts-off-tomorrow-use-google-takeout-and-reader-is-dead-to-backup/" rel="alternate"></link><updated>2013-06-30T10:29:00-04:00</updated><author><name>mr.rcollins</name></author><id>tag:ryancollins.org,2013-06-30:2013/06/30/google-reader-shuts-off-tomorrow-use-google-takeout-and-reader-is-dead-to-backup/</id><summary type="html">&lt;p&gt;Tomorrow Google Reader shuts off, have you grabbed your data? The easiest way to backup your subscriptions from Google Reader is to use &lt;a href="https://www.google.com/takeout/?pli=1"&gt;Google Takeout&lt;/a&gt;. This will give you a .zip file with a lot of data, including a subscriptions.xml which you can import into any RSS reader that accepts an OPML file.&lt;/p&gt;
&lt;p&gt;This is fine for your list of subscriptions, but I have been using Google Reader as a particular search engine, allowing me to search for items that I have read. I lost this ability with Google Takeout, but then I came across &lt;a href="http://readerisdead.com/"&gt;Reader is Dead&lt;/a&gt;. Mihai Parparita has created a couple of scripts that back up not only your subscriptions, but also all the items in Google Reader. For me, it was 928,981 items to be downloaded.&lt;/p&gt;
&lt;p&gt;Under OS X the script ran right out of the box. If you are on Windows, you will need to install Python first.&lt;/p&gt;</summary><category term="rss"></category><category term="googlereader"></category></entry><entry><title>Following lots of people on Twitter? You need ReadTwit</title><link href="http://ryancollins.org/2010/01/12/following-lots-of-people-on-twitter-you-need-readtwit/" rel="alternate"></link><updated>2010-01-12T08:06:00-05:00</updated><author><name>mr.rcollins</name></author><id>tag:ryancollins.org,2010-01-12:2010/01/12/following-lots-of-people-on-twitter-you-need-readtwit/</id><summary type="html">&lt;div style="float:right;"&gt;
[![10th November 314/365][]][]  
&lt;small&gt;[![Creative Commons License][]][] [photo][] credit:
[fifikins][]&lt;/small&gt;

&lt;/div&gt;

&lt;p&gt;A couple of months ago I decided to expand my use of Twitter, and began
following more and more people in the education community. This was
awesome, until I realized I could not keep up with the barrage of data
that I was being given. In November I started brainstorming ideas on how
to keep up. I noticed in any of my twitter clients that they were not
grabbing all the tweets that had been posted from the last time I
checked. The reason being is the API only gives you the last 200 tweets,
and for me that was about 40 minutes worth.&lt;/p&gt;
&lt;p&gt;My first course of action was to write some software that would grab the
tweets from my [@mr_rcollins][] timeline, parse the info and store it
in a MySQL database. Besides pulling out the data I was interested in of
each tweet, I also stored the complete tweet. This became impractical,
since in a month the complete tweets themselves occupied 4.2GB! I
stopped storing the complete tweets which left me with a 20MB database
after a 5 weeks of collecting, which was a lot more manageable.&lt;/p&gt;
&lt;p&gt;The next step was to start parsing the tweet's text for urls, resolve
any shortened urls, and dump them into another table for me to peruse.
While I got that software working, I came across &lt;a href="http://readtwit.com"&gt;ReadTwit.com&lt;/a&gt;. This
is a great service that will take your timeline, parse out the urls,
resolve shortened links, and give you a RSS feed that you can subscribe
to in your favorite RSS reader (I use &lt;a href="http://google.com/read"&gt;Google Reader&lt;/a&gt;. Now I just go
through Reader like normal, and am able to tag/star important sites that
are posted to my Twitter timeline.&lt;/p&gt;
&lt;p&gt;[&lt;img alt="10th November 314/365" src="http://farm3.static.flickr.com/2763/4091878747_a0282c9255_m.jpg" /&gt;]: http://www.flickr.com/photos/25925793@N00/4091878747/
    "10th November 314/365"
  [&lt;img alt="Creative Commons License" src="http://ryancollins.org/wp/wp-content/plugins/photo-dropper/images/cc.png" /&gt;]: http://creativecommons.org/licenses/by/2.0/
    "Attribution License"&lt;/p&gt;</summary><category term="rss"></category><category term="twitter"></category></entry><entry><title>Language arts teachers, take note, experience Bram Stoker's Dracula in real time</title><link href="http://ryancollins.org/2009/05/07/language-arts-teachers-take-note-experience-bram-stokers-dracula-in-real-time/" rel="alternate"></link><updated>2009-05-07T12:24:00-04:00</updated><author><name>mr.rcollins</name></author><id>tag:ryancollins.org,2009-05-07:2009/05/07/language-arts-teachers-take-note-experience-bram-stokers-dracula-in-real-time/</id><summary type="html">&lt;p&gt;&lt;a href="http://dracula-feed.blogspot.com/"&gt;Dracula&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Experience Bram Stoker's Dracula in a new way -- in real time. Dracula
is an epistolary novel (a novel written as a series of letters or
diary entries,) and this blog will publish each diary entry on the day
that it was written by the narrator so that the audience may
experience the drama as the characters would have.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What a cool way to introduce classic literature to student's brought up
with blogs and social networking. I've subscribed to the feed and can't
wait to read the novel through &lt;a href="http://google.com/reader/"&gt;Google Reader&lt;/a&gt;.&lt;/p&gt;
&lt;div class="zemanta-pixie"&gt;
![][]

&lt;/div&gt;

&lt;/p&gt;</summary><category term="blog"></category><category term="dracula"></category><category term="google reader"></category><category term="rss"></category></entry></feed>